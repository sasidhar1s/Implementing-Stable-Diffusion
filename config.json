{
    "paths": {
        "image_dir": "/Data2/sasi/Text2img_dataset/images_256",
        "captions_file": "/Data2/sasi/Text2img_dataset/captions.json",
        "validation_prompts_file": "/Data2/sasi/combined_dataset/validation_prompts.json",
        "resume_checkpoint": null
    },
    "training_parameters": {
        "total_iterations": 300000,
        "batch_size_per_gpu": 24,
        "learning_rate": 0.0001,
        "weight_decay": 0.01,
        "warmup_iterations": 6000,
        "max_grad_norm": 1.0,
        "mixed_precision": true,
        "caption_dropout_prob": 0.15,
        "ema_decay": 0.9999,
        "gradient_accumulation_steps": 1  
    },
    "model_parameters": {
        "image_size": 256,
        "latent_channels": 4,
        "context_dim": 768,
        "vae_model": "stabilityai/sd-vae-ft-mse",
        "image&text_encoding_model": "openai/clip-vit-large-patch14"
    },
    "diffusion_schedule": {
        "timesteps": 1000,
        "beta_start": 0.00085,
        "beta_end": 0.012
    },
    "sampling_parameters": {
        "print_frequency": 200,
        "save_frequency": 30000,
        "sample_frequency": 7500,
        "cfg_scale": 7.5,
        "clip_denoised": true,
        "repeat_noise": false,
        "num_inference_steps": 100
    }
}